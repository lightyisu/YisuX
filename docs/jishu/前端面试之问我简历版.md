---
catalog:
  - jishu
date: '2026-01-28 08:00:00'
type: Post
slug: fdwadwa
title: 前端面试之问我简历版
status: Draft
urlname: 2f6e9dc9-c245-8060-9e3d-c26729162904
updated: '2026-01-29 11:36:00'
---

## **AI和我不得不向面试官掰扯的事**


我本科是数字媒体技术，其实从本科开始就一直在做前端相关的事情，包括课程设计、项目和后面的实习。硕士选择人工智能，主要是出于两个原因：
一方面是希望系统性地补强自己的**计算机基础和建模能力**，另一方面我对**复杂系统、数据和性能问题**本身比较感兴趣。从长期来看，我更希望成为一个工程能力很强、同时理解底层原理的前端工程师，而不是纯研究方向。因为学校里也不可能开设前端底层研究的学位所以从人工智能的角度入手不仅能够拓宽视野也能够拉开自己的技术纵深。并且在未来自己会尝试前端和AI结合的项目或者对前端的底层进行一个纵向的学习。在使用 AI 工具（比如 Claude Code）时，我会更清楚它的能力边界，以及更理解AI工具对前端工程的可扩展可探索的地方。而且很多前端技术周刊已经转型成AI+前端的应用内容都在探索AI在前端的最佳实践，我觉得这个学习对我来说是有帮助的。


**「那你为什么不直接做 AI / 算法？」**


我尝试过，也做过比较深入的研究，但我个人感受到的差异是：
算法和研究的正反馈周期相对较长，而前端工程中，我可以更快地看到自己的工作被用户直接使用，这种反馈会让我更有动力持续投入。


**「那你以后会不会又转回 AI？」**


我现在非常清楚自己希望在工程能力上继续深挖，而前端的深度和复杂度本身也完全足够支撑长期发展。如果未来 AI 能在工程侧发挥价值，我更希望是以工程师的身份去使用和整合 AI，而不是转成研究角色。


**「那你读研这段经历对前端有什么实际帮助？」**


第一是对复杂问题的拆解能力，比如在做音频同步、多状态协调这种问题时，我会习惯先建模，再落代码；
第二是对性能和系统稳定性的敏感度，这在前端工程中其实非常重要；
第三是让我在使用 AI 工具（比如 Claude Code）时，更清楚它的能力边界，不会盲目依赖。


探索AI在前端的最佳实践，我觉得这个学习对我来说是有帮助的。


## 个人优势补充


webpack我已经很久没碰了 因为vite的原因 面试官可能会问随便讲一下


## Webpack


Webpack 本质上是一个模块打包器，它会从入口文件出发，把项目中用到的各种资源，比如 JS、CSS、图片等，都当成模块来处理，最终打包成浏览器可以直接运行的资源。


它的核心流程是：**entry → loader 转换 → plugin 扩展 → output 输出**。


在实际项目中，我主要用 Webpack 做过一些常见配置，比如通过 loader 处理 CSS、图片资源，通过 plugin 做代码压缩、环境变量注入，以及区分开发和生产环境配置。
loader 主要负责**把一种类型的模块转换成 Webpack 能识别的模块**，比如把 SCSS 转成 CSS，把 ES6 转成 ES5；
plugin 更像是介入 Webpack 的整个构建生命周期，用来做更宏观的事情，比如代码压缩、资源优化、生成 HTML 文件等。



**webpack应用**


比较常见的是做过代码分包，比如通过 splitChunks 把第三方库和业务代码拆开；


生产环境开启压缩、去掉无用代码；


还有就是区分开发和生产配置，保证开发体验和构建体积。


**与Vite**


Webpack 在开发时是先整体打包再启动服务，而 Vite 是基于 ES Module，开发阶段基本是按需编译，所以冷启动和热更新会快很多。


但在生产构建阶段，Vite 其实底层还是会用到 Rollup，和 Webpack 在目标上是相似的。打包构建结束后内部的模块化


## 原子化工具比如tailwindcss的原理


TailwindCSS 本质上是一套**原子化 CSS 方案**，它把常见的样式拆成非常细粒度的单一职责 class，比如 `flex`、`p-4`、`text-center`，通过组合 class 来完成样式，而不是为每个组件单独写语义化 CSS。


在实现层面，Tailwind 是在**构建阶段**扫描项目中用到的 class 名，根据配置文件生成对应的 CSS，而不是在运行时动态计算。


同时它通过 **JIT（Just-In-Time）编译** 和 **未使用样式裁剪**，保证最终产物只包含实际用到的样式，避免 CSS 体积膨胀。


原子化 CSS 则是把样式拆到最小单位，每个 class 只负责一个样式属性，通过组合来完成 UI。


Tailwind好处是不带无用CSS JIT扫描页面使用的CSS按需引入


## 咪鼠#1


### 1.Web Audio API


和`<audio>`浏览器给你的成品播放器不同 `Web Audio API`是自定义的音频流水线 相当于Web的音频工具包

- 音频是“数据流”
- 有独立的 **AudioContext 时间轴**
- 可以接：解码、处理、分析、输出
- **时间稳定、精度高**
- 硬件时钟

性能优化：


`audio.currentTime` 依赖浏览器渲染，页面卡顿、tab 切后台会飘 所以不用


`audioContext.currentTime`和渲染线程解耦 更稳定、更适合做同步


缺点就是需要自己写一点界面逻辑，手动维护一些时间逻辑


**精度和性能是核心诉求不得不用** 


因为既要在会议系统里的**字幕做一些滚动，标记，删除，以及批量管理的操作(DOM操作+JS计算）**，主线程的业务代码很多，如果用HTML5 Audio会导致时钟的小偏移同时也可能造成一些字幕的偏移这在业务中是不能出现的。因为会议记录往往是连续的句话，时间戳很紧凑。需要精准的时间戳。
参考了 **Google Meet** 和 **剪映** 处理音频流的思路，选择用 **Web Audio API** 的硬件时钟来驱动 UI
我的时钟是基于硬件音频采样率的，不论主线程写了多少业务代码，时钟永远不会飘移。这保证了 2 小时会议记录的字幕同步精度始终在帧级以内


### 2.字幕滚动匹配算法


使用requestAnimationFrame 里更新 UI


**索引预计算（滚动）：**


在加载页面后扫描收到的字幕数据，会根据时间顺序进行字幕的索引，将音频时间和字幕时间戳匹配提取出通过索引切分成对应的字幕分块的一个映射表，通过维护这个映射表做到拖动时自动快速匹配字幕。


**虚拟列表字幕展示：**


在字幕条数比较多的情况下，如果一次 性渲染所有字幕节点，会有不必要的 DOM 开销，所以我在展示层做了类似**虚拟列表的处理**，只渲染当前可视窗口附近的字幕项，其余的通过占位高度来保持滚动位置。


**拖动同步：**


在拖动音频轴的时候要做到实时的同步拖动字幕滚动，字幕滚动始终绑定当前时间轴状态，在拖动过程中实时派生渲染对应字幕。并且通过之前预计算的索引直接返回合适的字幕区域。


### 咪鼠#2


### 1.多组件状态不一致


在这个音频模块里，播放状态、当前时间、拖动状态会被多个组件同时依赖，如果各组件各自维护或通过 props 传递，很容易出现状态不同步，导致重复渲染和短暂的 UI 卡顿。在全局状态中我只保留音频播放和时间轴这些必须共享的核心状态，像进度百分比、当前字幕索引这类 UI 派生状态，我放在组件内部通过计算得到，避免不必要的全局依赖和重复渲染。


把计算状态不写进VueX中，只写进核心状态降低全局依赖面。降低渲染成本。


## 讯飞


## Hexo插件


PPT/DOCX
**介绍：**我是通过 Hexo 提供的 标签插件机制，注册了一个自定义的 `ppt` 标签。
在构建阶段，当 Hexo 解析 Markdown 时遇到 `{% ppt xxx.pptx %}` 这样的标签，我会返回一段已经拼装好的 HTML，用来在最终页面中直接渲染 PPT 预览。


**原理：**插件内部并没有自己去解析 PPT 文件，而是复用了一个现成的前端库。在构建阶段我会通过 Node.js 读取该库所需的 JS 和 CSS 资源，然后在生成的 HTML 中以内联的方式注入这些资源，并初始化对应的渲染逻辑。
**使用：**在 Markdown 中只需要通过一个自定义标签声明 PPT 地址，比如 `{% ppt url %}`，插件会在构建时把这个标签替换成对应的 HTML 预览结构。


总结：这是一个基于 Hexo 构建生命周期的内容扩展插件，通过模板注入实现文档预览，并没有涉及复杂的文件解析逻辑。


## 数字人ws直播


这个项目本身是一个偏应用层的 Demo，我主要负责的是 Web 端对 WebRTC 流的接入、播放以及基础交互ws，并没有涉及底层协议或服务端实现。


在这个 Demo 里：

1. WebSocket 负责交换 offer / answer（不传视频）
2. RTCPeerConnection 负责建立媒体连接
3. 视频流通过 ontrack 进 video 标签

WebSocket作为WebRTC的信令传输通道


## 网盘


对于大文件上传，前端会将文件按固定大小进行切片，通过标识文件唯一性的 hash 或 id，将切片逐个上传给后端，由后端负责合并和校验。这样可以降低单次上传失败的成本，也方便后续做断点续传。


实现：



1️⃣用 `File.slice` 切文件


设置切片大小 引入sparkmd5获取整个文件的hash值 把所有数据包裹在formData 上传完切片请求合并此时通知上传成功


**切片上传使用 FormData，是因为它最适合承载二进制文件数据，同时还能方便地携带分片相关的元信息。**
2️⃣ 每个切片带上必要信息


```javascript
{
  fileId,      // 文件唯一标识
  chunkIndex,  // 当前第几块
  totalChunks  // 总块数
  filehash //文件标识
}
```


断点续传：原理再上传没传完的块


秒传：上传文件时，先提交文件的哈希值


优化切片多的问题：1限制同时上传的分片数量使用“动态任务池”Promise.race() 2切片大小动态调整 3使用 Web Worker





在项目中对 Axios 做了一层统一封装，主要包括请求和响应拦截、统一的错误处理、以及 token 的自动携带，减少业务代码中重复逻辑。拦截器更多是用来约束请求行为和统一处理副作用，而不是承载认证本身。


登录态主要通过 cookie 保存 token，在请求时由 Axios 拦截器自动携带，前端根据接口返回状态判断是否需要重新登录。


在表单输入和搜索等高频操作中使用防抖，减少无意义请求，同时对未提交的表单内容做本地缓存，提升用户体验。

